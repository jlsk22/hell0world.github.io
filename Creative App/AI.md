---
AI Discussion
---
By now, you've ingested a great deal of material and information about data, automation, and AI. You should be thinking and 
writing about what aspects, issues, problems, or hunches are developing for you, and what stands out. Can you connect things 
back to your own personal experience, family, community, country? Write a post about what is brewing in your mind, and what 
you'd like to explore for your final project. Make sure to submit it using the homework form under week 11.1.

What seems to stand out most of me about the information I've learned thus far, is how much of a feedback loop our culture,
society, and technology have with each other. It is never one-sided and it is constantly shifting and changing depending all
three. It's interesting to me how much we humanize tech with our prejudice and biased, like how AI is infamously racist
towards people of color and that leaks into our police systems that utilize it. Another example being AI programs we create 
personalities for and build to serve us don't escape our sexist nature, such as Alexa. Every single AI 
servant is female because "marketing studies" found that people believe women's voices are more caring and trusting; 
whereas male voices, are authoritative but more trusting when being sold something and therefore, better for GPS interfaces.
What's most notable to me about it though is that we didn't have to gendersize AI to be like us- we could've created a whole
new gender neutral or genderless AI movement. I understand the intent through marketing and profit reasons because the 
porduct is supposed to be catered for our comfort, so of course make it sound like us and respond like us. But something even
about trying to turn technology into us feels wrong to me. Yes, new frontiers are a blank slate that we can paint anything onto 
but why do we again and again choose to re-create ourselves? Is it ego? Convenience? Lack of imagination?
